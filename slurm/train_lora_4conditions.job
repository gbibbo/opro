#!/bin/bash
#SBATCH --job-name=train_4cond
#SBATCH --partition=3090
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=8
#SBATCH --mem=48G
#SBATCH --time=16:00:00
#SBATCH --output=logs/train_4cond_%j.out
#SBATCH --error=logs/train_4cond_%j.err

# ==============================================================================
# Train LoRA on 4-Condition Dataset
# ==============================================================================
#
# Fine-tunes Qwen2-Audio-7B-Instruct with LoRA on the expanded dataset
# containing all 4 psychometric conditions:
# - Duration (8 levels)
# - SNR (6 levels)
# - Band Filter (3 types)
# - Reverb/T60 (3 levels)
#
# Expected training time: ~12-16 hours with ~23k samples
#
# ==============================================================================

set -euo pipefail

SEED=${1:-42}

echo "============================================"
echo "TRAIN LORA ON 4-CONDITION DATASET"
echo "============================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURM_NODELIST"
echo "Seed: $SEED"
echo "Start time: $(date)"
echo "============================================"

mkdir -p logs

# Setup environment
export HF_HOME="/mnt/fast/nobackup/users/$USER/.cache/huggingface"
export TRANSFORMERS_CACHE="$HF_HOME/transformers"
export HF_HUB_CACHE="$HF_HOME/hub"
export PYTORCH_CUDA_ALLOC_CONF="expandable_segments:True"
mkdir -p "$HF_HOME" "$TRANSFORMERS_CACHE" "$HF_HUB_CACHE"

# Activate conda
source ~/miniconda3/etc/profile.d/conda.sh 2>/dev/null || source ~/.bashrc
conda activate opro || conda activate qwen_audio || { echo "ERROR: Could not activate conda"; exit 1; }
echo "Conda environment: $CONDA_DEFAULT_ENV"

# Ensure dependencies
pip install bitsandbytes peft accelerate transformers --quiet 2>/dev/null || true

# GPU info
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv

# Paths
TRAIN_CSV="data/processed/expanded_4conditions/train_metadata.csv"
VAL_CSV="data/processed/expanded_4conditions/dev_metadata.csv"
OUTPUT_DIR="checkpoints/qwen_lora_4conditions_seed${SEED}"

# Check data exists
if [ ! -f "$TRAIN_CSV" ]; then
    echo "ERROR: Training data not found at $TRAIN_CSV"
    echo "Please run generate_full_conditions_dataset.job first"
    exit 1
fi

# Count samples
TRAIN_COUNT=$(wc -l < "$TRAIN_CSV")
VAL_COUNT=$(wc -l < "$VAL_CSV")
echo ""
echo "Dataset:"
echo "  Train: $((TRAIN_COUNT - 1)) samples"
echo "  Val: $((VAL_COUNT - 1)) samples"
echo ""

echo "Configuration:"
echo "  Output: $OUTPUT_DIR"
echo "  Epochs: 3"
echo "  Batch size: 1 (effective: 16 with grad accum)"
echo "  Learning rate: 5e-5"
echo "  LoRA r: 16, alpha: 32"
echo "  Seed: $SEED"
echo ""

mkdir -p "$OUTPUT_DIR"

# Run training
python scripts/finetune_qwen_audio.py \
    --seed $SEED \
    --output_dir "$OUTPUT_DIR" \
    --train_csv "$TRAIN_CSV" \
    --val_csv "$VAL_CSV" \
    --num_epochs 3 \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 16 \
    --learning_rate 5e-5 \
    --lora_r 16 \
    --lora_alpha 32

EXIT_CODE=$?

echo ""
echo "============================================"
echo "TRAINING COMPLETE"
echo "============================================"
echo "Exit code: $EXIT_CODE"
echo "End time: $(date)"

if [ $EXIT_CODE -eq 0 ]; then
    echo ""
    echo "Model saved to: $OUTPUT_DIR"
    ls -la "$OUTPUT_DIR"/final/ 2>/dev/null || ls -la "$OUTPUT_DIR"/ 2>/dev/null
fi

exit $EXIT_CODE
