# OPRO Qwen - Speech Detection with Psychoacoustic Evaluation

![Baseline Complete](https://img.shields.io/badge/baseline-complete-brightgreen)
![DT75](https://img.shields.io/badge/DT75-35ms-blue)
![SNR--75](https://img.shields.io/badge/SNR--75--3dB@1s-orange)
![Paper Ready](https://img.shields.io/badge/status-paper--ready-success)

**Rigorous psychophysical evaluation of Qwen2-Audio-7B-Instruct for binary speech detection.**

Implements MLE psychometric curve fitting with bootstrap CIs (Wichmann & Hill 2001), pseudo-RÂ² goodness-of-fit (McFadden, Tjur), and GLMM interaction analysis (Moscatelli et al. 2012).

---

## ğŸ¯ Baseline Results (FROZEN v1.0)

### Dev Set (n=70 clips) - PAPER-READY

| Metric | Value | CI95 | RÂ² | Status |
|--------|-------|------|-----|--------|
| **DT75** (Duration threshold) | **34.8 ms** | [19.9, 64.1] | 0.063 | âœ… Robust |
| **SNR-75** (1000ms) | **âˆ’2.9 dB** | [âˆ’12.0, +8.5] | 0.067 | âœ… Robust |
| **GLMM Interaction** | **p<0.001** | - | 0.042 | âœ… Significant |

**Interpretation**:
- Model requires **35 ms** of audio for 75% correct speech detection
- Tolerates SNR down to **âˆ’3 dB** at 1 second duration
- **Confirmed SNRÃ—Duration interaction**: Longer stimuli allow better SNR utilization

### Test Set (n=17 clips) - HOLD-OUT

| Metric | Dev | Test | Notes |
|--------|-----|------|-------|
| Accuracy | 0.583 | 0.335 | Test harder (smaller, tougher clips) |
| Clip Accuracy | 0.690 | 0.353 | Validates no overfitting |

---

## ğŸ“Š Key Findings

### 1. Duration Psychometric Curve (Sprint 7)
- **DT50**: 23.3 ms [15.5, 36.3]
- **DT75**: 34.8 ms [19.9, 64.1] â† **PRIMARY METRIC**
- **McFadden RÂ²**: 0.063
- **Tjur RÂ²**: 0.078
- **Status**: âœ… Monotonic, narrow CIs, PAPER-READY

### 2. SNR Psychometric Curves (Sprint 8 - Stratified)

| Duration | SNR-75 (dB) | CI95 | RÂ² | Status |
|----------|-------------|------|-----|--------|
| **1000 ms** | **âˆ’2.9** | [âˆ’12.0, +8.5] | 0.067 | âœ… Robust |
| **200 ms** | **+16.0** | [âˆ’0.7, +20.0] | 0.029 | âœ… At limit |
| **80 ms** | **>+20** | [+15.3, +20.0] | 0.006 | âš ï¸ Out of range |
| **20 ms** | **>+20** | [+20.0, +20.0] | âˆ’0.023 | âš ï¸ Chance level |

**Pattern**: Longer duration â†’ lower SNR required (temporal integration)

### 3. GLMM: SNRÃ—Duration Interaction

**Model**: `logit(P) ~ SNR + log(Duration) + SNR:log(Duration) + (1|clip)`

| Effect | Î² | SE | p-value | Interpretation |
|--------|---|-----|---------|----------------|
| SNR | âˆ’0.045 | 0.018 | 0.011* | Higher SNR â†’ better |
| log(Duration) | +0.295 | 0.066 | <0.001*** | Longer â†’ better |
| **SNR:log(Duration)** | **+0.014** | **0.004** | **<0.001***| **SNR benefit scales with duration** |

**Pseudo-RÂ²**: McFadden = 0.042, Tjur = 0.056

---

## ğŸš€ Quick Start

### Installation
```bash
git clone <repository-url>
cd OPRO-Qwen
pip install -r requirements.txt
```

### Reproduce Baseline (Dev Set)
```bash
# 1. Evaluate dev set (~15 min with GPU)
python scripts/evaluate_with_robust_metrics.py

# 2. Fit duration curves
python scripts/fit_psychometric_curves.py --n_bootstrap 1000

# 3. Generate factorial SNRÃ—Duration dataset
python scripts/generate_snr_duration_crossed.py

# 4. Evaluate factorial dataset
python scripts/evaluate_snr_duration_crossed.py

# 5. Fit stratified SNR curves
python scripts/fit_snr_curves_stratified.py

# 6. GLMM interaction analysis
python scripts/fit_glmm_snr_duration.py
```

### Reproduce Test Set (Hold-Out)
```bash
# Evaluate test set with frozen baseline
python scripts/evaluate_test_set_complete.py

# Fit curves on test
python scripts/fit_psychometric_curves.py \
  --predictions results/test_set_final/predictions.parquet \
  --output_dir results/test_set_final/duration_curves
```

---

## ğŸ“ Project Structure

```
OPRO-Qwen/
â”œâ”€â”€ BASELINE_FINAL_REPORT.md      # Complete baseline documentation
â”œâ”€â”€ BASELINE_FREEZE.md             # Technical freeze documentation
â”œâ”€â”€ README.md                      # This file
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ conditions_final/      # Full dataset (duration, SNR, band, RIR)
â”‚       â”œâ”€â”€ snr_duration_crossed/  # Factorial 4Ã—8 dataset (Sprint 8)
â”‚       â””â”€â”€ subset_20clips_balanced.csv  # Factorial subset metadata
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ sprint6_robust/            # Dev/test split, robust metrics
â”‚   â”œâ”€â”€ psychometric_curves/       # Duration curves (Sprint 7)
â”‚   â”œâ”€â”€ sprint8_factorial/         # Factorial evaluation
â”‚   â”œâ”€â”€ sprint8_stratified/        # Stratified SNR curves
â”‚   â”œâ”€â”€ sprint8_glmm/              # GLMM interaction analysis
â”‚   â””â”€â”€ test_set_final/            # Test set results (hold-out)
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ evaluate_with_robust_metrics.py      # Main evaluation
â”‚   â”œâ”€â”€ fit_psychometric_curves.py           # Duration/SNR curves (Sprint 7)
â”‚   â”œâ”€â”€ generate_snr_duration_crossed.py     # Factorial dataset gen
â”‚   â”œâ”€â”€ evaluate_snr_duration_crossed.py     # Factorial evaluation
â”‚   â”œâ”€â”€ fit_snr_curves_stratified.py         # Stratified fitting
â”‚   â”œâ”€â”€ fit_glmm_snr_duration.py             # GLMM analysis
â”‚   â””â”€â”€ evaluate_test_set_complete.py        # Test set pipeline
â”‚
â””â”€â”€ src/qsm/
    â”œâ”€â”€ audio/
    â”‚   â”œâ”€â”€ slicing.py             # Duration extraction & padding
    â”‚   â”œâ”€â”€ noise.py               # SNR mixing (validated)
    â”‚   â”œâ”€â”€ bandlimit.py           # Band-limiting
    â”‚   â””â”€â”€ reverb.py              # Reverberation
    â””â”€â”€ models/
        â””â”€â”€ qwen_audio.py          # Qwen2-Audio wrapper
```

---

## ğŸ“š Documentation

### Primary Documents
- **[BASELINE_FINAL_REPORT.md](BASELINE_FINAL_REPORT.md)** - Complete results, paper-ready tables, methodology
- **[BASELINE_FREEZE.md](BASELINE_FREEZE.md)** - Technical documentation of frozen artifacts
- **[SPRINT8_SPECIFICATION.md](SPRINT8_SPECIFICATION.md)** - Factorial design rationale

### Historical Sprints
- **[SPRINT6_SUMMARY.md](SPRINT6_SUMMARY.md)** - Robust evaluation framework
- **[SPRINT7_REVISED_SUMMARY.md](SPRINT7_REVISED_SUMMARY.md)** - MLE psychometric curves
- **[HALLAZGOS_SNR_INVESTIGATION.md](HALLAZGOS_SNR_INVESTIGATION.md)** - SNR validation

---

## ğŸ”¬ Methodology

### Psychometric Curve Fitting
- **Method**: Maximum Likelihood Estimation (MLE) with binomial likelihood
- **Parameters**: Fixed Î³=0.5 (chance level), free lapse Î» âˆˆ [0, 0.1]
- **CIs**: Bootstrap resampling (n=1000), clustered by clip_id
- **Goodness-of-fit**: McFadden & Tjur pseudo-RÂ² (appropriate for logistic models)
- **Reference**: Wichmann & Hill (2001a, 2001b), *Perception & Psychophysics*

### GLMM Interaction Analysis
- **Model**: Generalized Estimating Equations (GEE) with logit link
- **Formula**: `logit(P) ~ SNR + log(Duration) + SNR:log(Duration)`
- **Correlation**: Exchangeable (accounts for repeated measures within clips)
- **Reference**: Moscatelli et al. (2012), *Journal of Vision*

### Pseudo-RÂ² for Logistic Regression
- **McFadden RÂ²**: Compares log-likelihood of model vs null (intercept-only)
- **Tjur RÂ²**: Difference in mean predicted probabilities between classes
- **References**: McFadden (1974), Tjur (2009)

---

## ğŸ¯ Model Configuration (FROZEN)

```python
Model: Qwen/Qwen2-Audio-7B-Instruct
Quantization: 4-bit (bitsandbytes)
Device: CUDA
Temperature: 0.0  # Deterministic
Seed: 42  # Reproducible
Sample Rate: 16 kHz
Auto-padding: <2000ms â†’ 2000ms (noise amplitude: 0.0001)

Prompt (FROZEN):
"<|audio_bos|><|AUDIO|><|audio_eos|>Does this audio contain human speech?
Reply with ONLY one word: SPEECH or NON-SPEECH."
```

---

## ğŸ“Š Dataset

### Dev Set
- **Clips**: 70 (32 SPEECH, 38 NON-SPEECH)
- **Variants per clip**: 20
  - 8 duration levels: {20, 40, 60, 80, 100, 200, 500, 1000} ms
  - 6 SNR levels: {âˆ’10, âˆ’5, 0, +5, +10, +20} dB
  - 3 band-limiting conditions
  - 3 room impulse responses (RIR)
- **Total samples**: 1400

### Test Set
- **Clips**: 17 (8 SPEECH, 9 NON-SPEECH)
- **Variants per clip**: 20 (same as dev)
- **Total samples**: 340

### Factorial SNRÃ—Duration (Sprint 8)
- **Clips**: 20 (10 SPEECH, 10 NON-SPEECH from dev)
- **Design**: 4 durations Ã— 8 SNR levels = 32 conditions
  - Durations: {20, 80, 200, 1000} ms
  - SNR: {âˆ’20, âˆ’15, âˆ’10, âˆ’5, 0, +5, +10, +20} dB
- **Total samples**: 640
- **Balance**: 50/50 SPEECH/NON-SPEECH per condition âœ…

---

## ğŸ“ˆ Results Files

### Paper-Ready Outputs
- `results/psychometric_curves/duration_curve.png` - Duration psychometric curve
- `results/sprint8_stratified/snr_curves_stratified.png` - 4 SNR curves by duration
- `results/sprint8_glmm/isoperformance_contour.png` - DurationÃ—SNR plane with 75% line
- `results/psychometric_curves/psychometric_results.json` - All thresholds & RÂ²

### Data Files
- `results/sprint6_robust/dev_clips.parquet` - Dev set predictions (clip-level)
- `results/sprint8_factorial/predictions.parquet` - Factorial predictions (640 samples)
- `results/test_set_final/test_clips.parquet` - Test set predictions

---

## ğŸ·ï¸ Git Tags

- **`v1.0-baseline-dev`**: Dev set results frozen
- **`v1.0-baseline-final`**: Complete baseline (dev + test)

---

## ğŸ“ Paper-Ready Content

See **[BASELINE_FINAL_REPORT.md](BASELINE_FINAL_REPORT.md)** for:
- âœ… Methods section (fully written)
- âœ… Results section (fully written)
- âœ… Tables (DT75, SNR-75 by duration, GLMM)
- âœ… Standard references (Wichmann, McFadden, Moscatelli)
- âœ… Figures with captions

---

## ğŸ” Key Citations

1. **Wichmann, F. A., & Hill, N. J. (2001a).** The psychometric function: I. Fitting, sampling, and goodness of fit. *Perception & Psychophysics*, 63(8), 1293-1313.

2. **Wichmann, F. A., & Hill, N. J. (2001b).** The psychometric function: II. Bootstrap-based confidence intervals and sampling. *Perception & Psychophysics*, 63(8), 1314-1329.

3. **McFadden, D. (1974).** Conditional logit analysis of qualitative choice behavior. In P. Zarembka (Ed.), *Frontiers in Econometrics* (pp. 105-142).

4. **Tjur, T. (2009).** Coefficients of determination in logistic regression models. *The American Statistician*, 63(4), 366-372.

5. **Moscatelli, A., Mezzetti, M., & Lacquaniti, F. (2012).** Modeling psychophysical data at the population-level. *Journal of Vision*, 12(11):26.

---

## ğŸš« Baseline is FROZEN

**Do NOT modify**:
- Model configuration (quantization, temperature, seed)
- Prompt template
- Psychometric fitting procedure
- Dev/test split

**For comparisons**:
- Prompt engineering â†’ create new version tag (v1.1+)
- Fine-tuning â†’ create new version tag (v2.0+)
- Architecture change â†’ new baseline

---

## ğŸ”„ Reproducing Results

All results are deterministic (seed=42, temperature=0):

```bash
# Complete pipeline (dev set)
bash run_complete_pipeline.sh  # ~2 hours with GPU

# Or step-by-step (as shown in Quick Start)
```

**Expected outputs match exactly**:
- DT75 = 34.8 ms [19.9, 64.1]
- SNR-75(1000ms) = âˆ’2.9 dB [âˆ’12.0, +8.5]
- GLMM: p<0.001 for all effects

---

## ğŸ“ Academic Use

If you use this baseline or methodology, please cite:

```
[Add citation when paper is published]
```

Key methodological contributions:
- Rigorous psychophysical evaluation of LLM-based audio model
- MLE fitting with bootstrap CIs for audio thresholds
- GLMM for SNRÃ—Duration interaction in speech detection
- Factorial design for stratified psychometric analysis

---

## ğŸ“ Contact

[Add contact information]

---

## ğŸ“œ License

[Add license]

---

**Baseline Status**: âœ… COMPLETE (v1.0-baseline-final)
**Last Updated**: 2025-10-13
**Model**: Qwen2-Audio-7B-Instruct (zero-shot, 4-bit)
